{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "import skimage\n",
    "from skimage import measure\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import shuffle\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_paths(foldNames):\n",
    "  \n",
    "    paths = dict.fromkeys(foldNames)\n",
    "\n",
    "    for idx,g in enumerate(foldNames):\n",
    "        fileNames = [f for f in listdir(join(trainPath,g)) if isfile(join(trainPath,g, f))]\n",
    "        for i,f in enumerate(fileNames):\n",
    "            fileNames[i] = join(trainPath,g,f)     \n",
    "        paths[g] = fileNames\n",
    "        \n",
    "    return paths\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = io.imread(src)\n",
    "    im = resize(im, (ROWS, COLS))\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROWS = 9  #90 720\n",
    "COLS = 16 #160 1280\n",
    "CHANNELS = 3\n",
    "trainPath = '../train'\n",
    "testPath = '../test_stg1'\n",
    "fish_classes = [f for f in listdir(trainPath) if isdir(join(trainPath, f))]\n",
    "groupData = pd.DataFrame ({'group': fish_classes})\n",
    "fish_paths = get_paths(fish_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build x and y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx,fish in enumerate(fish_classes):\n",
    "    groupData.ix[idx,'num files'] = int(len(fish_paths[fish]))\n",
    "    \n",
    "files = []\n",
    "Y_cat = []\n",
    "\n",
    "for fish in fish_classes:\n",
    "    fish_files = fish_paths[fish]\n",
    "    files.extend(fish_files)\n",
    "    \n",
    "    y_fish = np.tile(fish, len(fish_files))\n",
    "    Y_cat.extend(y_fish)\n",
    "  \n",
    "Y_cat = np.array(Y_cat) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 3777\n",
      "Processed 1000 of 3777\n",
      "Processed 2000 of 3777\n",
      "Processed 3000 of 3777\n"
     ]
    }
   ],
   "source": [
    "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, f in enumerate(files): \n",
    "    im = read_image(f)\n",
    "    X_all[i] = im\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view resampled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAEqCAYAAAAxsqiNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlBJpACj1P1G56Rzx1TncAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a6e1190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_all[0]\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(im, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data\n",
    "* One hot encoding labels\n",
    "* Split data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding Labels\n",
    "#    Transform the categorical array Y_all into matrix of the same height, \n",
    "#    but with a boolean column for each category.\n",
    "Y_all = LabelEncoder().fit_transform(Y_cat)\n",
    "Y_all = np_utils.to_categorical(Y_all)\n",
    "\n",
    "# test_size: between 0 and 1. proportion of the dataset to include in the test split\n",
    "# random_state: Pseudo-random number generator state used for random sampling. How to shoose this?\n",
    "# stratify: this is ensuring that the split datasets are balanced, i.e. contains the same \n",
    "# percentage of classes\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_all, Y_all, \n",
    "                                                    test_size=0.2, random_state=23, \n",
    "                                                    stratify=Y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model\n",
    "using this example:\n",
    "https://www.kaggle.com/jeffd23/the-nature-conservancy-fisheries-monitoring/deep-learning-in-the-deep-blue-lb-1-279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'categorical_crossentropy'\n",
    "\n",
    "def center_normalize(x):\n",
    "    return (x - K.mean(x)) / K.std(x)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Activation(activation=center_normalize, input_shape=(ROWS, COLS, CHANNELS)))\n",
    "\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(len(fish_classes)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=objective, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2416 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 5s - loss: 1.9711 - val_loss: 1.8249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124075790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')        \n",
    "        \n",
    "model.fit(X_train, Y_train, batch_size=64, nb_epoch=1,\n",
    "              validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756/756 [==============================] - 0s     \n",
      "Validation Log Loss: 1.78604752819\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_valid, verbose=1)\n",
    "print(\"Validation Log Loss: {}\".format(log_loss(Y_valid, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 992/1000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# read in test photo set\n",
    "test_files = [im for im in os.listdir(testPath)]\n",
    "test = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "for i, im in enumerate(test_files): \n",
    "    test[i] = read_image(join(testPath,im))\n",
    "    \n",
    "#model predict\n",
    "test_preds = model.predict(test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00005.jpg</td>\n",
       "      <td>0.718651</td>\n",
       "      <td>0.394385</td>\n",
       "      <td>0.563580</td>\n",
       "      <td>0.354318</td>\n",
       "      <td>0.476741</td>\n",
       "      <td>0.421754</td>\n",
       "      <td>0.278019</td>\n",
       "      <td>0.578045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_00007.jpg</td>\n",
       "      <td>0.828790</td>\n",
       "      <td>0.329407</td>\n",
       "      <td>0.590444</td>\n",
       "      <td>0.265877</td>\n",
       "      <td>0.462128</td>\n",
       "      <td>0.377150</td>\n",
       "      <td>0.162928</td>\n",
       "      <td>0.624663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00009.jpg</td>\n",
       "      <td>0.828522</td>\n",
       "      <td>0.329704</td>\n",
       "      <td>0.589665</td>\n",
       "      <td>0.266147</td>\n",
       "      <td>0.462324</td>\n",
       "      <td>0.377669</td>\n",
       "      <td>0.163119</td>\n",
       "      <td>0.624307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_00018.jpg</td>\n",
       "      <td>0.858445</td>\n",
       "      <td>0.308022</td>\n",
       "      <td>0.598143</td>\n",
       "      <td>0.238534</td>\n",
       "      <td>0.457815</td>\n",
       "      <td>0.362104</td>\n",
       "      <td>0.132853</td>\n",
       "      <td>0.640205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00027.jpg</td>\n",
       "      <td>0.838145</td>\n",
       "      <td>0.319167</td>\n",
       "      <td>0.614553</td>\n",
       "      <td>0.258414</td>\n",
       "      <td>0.458660</td>\n",
       "      <td>0.362617</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.636650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_00005.jpg  0.718651  0.394385  0.563580  0.354318  0.476741  0.421754   \n",
       "1  img_00007.jpg  0.828790  0.329407  0.590444  0.265877  0.462128  0.377150   \n",
       "2  img_00009.jpg  0.828522  0.329704  0.589665  0.266147  0.462324  0.377669   \n",
       "3  img_00018.jpg  0.858445  0.308022  0.598143  0.238534  0.457815  0.362104   \n",
       "4  img_00027.jpg  0.838145  0.319167  0.614553  0.258414  0.458660  0.362617   \n",
       "\n",
       "      SHARK       YFT  \n",
       "0  0.278019  0.578045  \n",
       "1  0.162928  0.624663  \n",
       "2  0.163119  0.624307  \n",
       "3  0.132853  0.640205  \n",
       "4  0.157700  0.636650  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(test_preds, columns=fish_classes)\n",
    "submission.insert(0, 'image', test_files)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mkdir '../tflearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dnn_test1():\n",
    "    #needed to run this tensorflow operation in order to build the network and subsequently \n",
    "    #create the model, multiple times. Rebuilding without resetting the tf.Graph object produces\n",
    "    #errors. Could also get around this issue by restarting kernel, but that's annoying.\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        #input layer with shape of data specified. In this case, dimensions of our images, \n",
    "        #rows X cols X rgb array. The initial 'None' is for an unknown dimension reflecting the \n",
    "        #\"number of samples that are processed in a batch\"\n",
    "        net = input_data(shape=[None, ROWS, COLS, 3])\n",
    "        net = fully_connected(net, 72, activation='relu')\n",
    "        net = fully_connected(net, 8, activation='softmax')\n",
    "        net = regression(net)\n",
    "        return tflearn.DNN(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m1.53039\u001b[0m\u001b[0m | time: 0.950s\n",
      "| Adam | epoch: 001 | loss: 1.53039 - acc: 0.4781 -- iter: 3008/3021\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m1.53686\u001b[0m\u001b[0m | time: 0.954s\n",
      "| Adam | epoch: 001 | loss: 1.53686 - acc: 0.4678 -- iter: 3021/3021\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = dnn_test1()\n",
    "\n",
    "# Start training (apply gradient descent algorithm). Will want to specify multiple epochs \n",
    "# typically unless just testing\n",
    "model.fit(X_train, Y_train, n_epoch=1,\n",
    "          show_metric=True, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00005.jpg</td>\n",
       "      <td>0.718651</td>\n",
       "      <td>0.394385</td>\n",
       "      <td>0.563580</td>\n",
       "      <td>0.354318</td>\n",
       "      <td>0.476741</td>\n",
       "      <td>0.421754</td>\n",
       "      <td>0.278019</td>\n",
       "      <td>0.578045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_00007.jpg</td>\n",
       "      <td>0.828790</td>\n",
       "      <td>0.329407</td>\n",
       "      <td>0.590444</td>\n",
       "      <td>0.265877</td>\n",
       "      <td>0.462128</td>\n",
       "      <td>0.377150</td>\n",
       "      <td>0.162928</td>\n",
       "      <td>0.624663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00009.jpg</td>\n",
       "      <td>0.828522</td>\n",
       "      <td>0.329704</td>\n",
       "      <td>0.589665</td>\n",
       "      <td>0.266147</td>\n",
       "      <td>0.462324</td>\n",
       "      <td>0.377669</td>\n",
       "      <td>0.163119</td>\n",
       "      <td>0.624307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_00018.jpg</td>\n",
       "      <td>0.858445</td>\n",
       "      <td>0.308022</td>\n",
       "      <td>0.598143</td>\n",
       "      <td>0.238534</td>\n",
       "      <td>0.457815</td>\n",
       "      <td>0.362104</td>\n",
       "      <td>0.132853</td>\n",
       "      <td>0.640205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00027.jpg</td>\n",
       "      <td>0.838145</td>\n",
       "      <td>0.319167</td>\n",
       "      <td>0.614553</td>\n",
       "      <td>0.258414</td>\n",
       "      <td>0.458660</td>\n",
       "      <td>0.362617</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.636650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_00005.jpg  0.718651  0.394385  0.563580  0.354318  0.476741  0.421754   \n",
       "1  img_00007.jpg  0.828790  0.329407  0.590444  0.265877  0.462128  0.377150   \n",
       "2  img_00009.jpg  0.828522  0.329704  0.589665  0.266147  0.462324  0.377669   \n",
       "3  img_00018.jpg  0.858445  0.308022  0.598143  0.238534  0.457815  0.362104   \n",
       "4  img_00027.jpg  0.838145  0.319167  0.614553  0.258414  0.458660  0.362617   \n",
       "\n",
       "      SHARK       YFT  \n",
       "0  0.278019  0.578045  \n",
       "1  0.162928  0.624663  \n",
       "2  0.163119  0.624307  \n",
       "3  0.132853  0.640205  \n",
       "4  0.157700  0.636650  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model predict\n",
    "test_preds1 = model.predict(test)\n",
    "\n",
    "submission = pd.DataFrame(test_preds, columns=fish_classes)\n",
    "submission.insert(0, 'image', test_files)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [datasci]",
   "language": "python",
   "name": "Python [datasci]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
