{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "A [pip requirements file](https://pip.pypa.io/en/stable/user_guide/#requirements-files) can be found at: [/sashimdig/requirements.txt](../requirements.txt)\n",
    "\n",
    "Notable requirements\n",
    "\n",
    "|package    |version |\n",
    "|----       |-----   |\n",
    "|tensorflow | 0.10.0 |\n",
    "| tflearn   | 0.2.1  |\n",
    "\n",
    "\n",
    "----\n",
    "### [TFLearn installation instructions](http://tflearn.org/installation/)\n",
    "Must install older tensorflow version 0.10 (NOT the latest 1.0) to work w/ `tflearn`\n",
    "\n",
    "```\n",
    "# Mac OS X, CPU only, Python 3.4 or 3.5:\n",
    "$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0-py3-none-any.whl\n",
    "\n",
    "# Mac OS X, GPU enabled, Python 3.4 or 3.5:\n",
    "$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.10.0-py3-none-any.whl\n",
    "\n",
    "sudo -H pip3 install --upgrade $TF_BINARY_URL --ignore-installed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib\n",
    "import seaborn           as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from   os      import getcwd\n",
    "from   os      import listdir\n",
    "from   os.path import isfile, join, isdir\n",
    "\n",
    "import skimage\n",
    "from   skimage import measure\n",
    "from   skimage import io\n",
    "\n",
    "from   PIL     import Image\n",
    "\n",
    "from   sklearn.model_selection    import train_test_split\n",
    "from   sklearn.metrics            import log_loss\n",
    "from   sklearn.preprocessing      import LabelEncoder\n",
    "from   skimage.transform          import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from   tflearn.data_utils         import shuffle\n",
    "from   tflearn.layers.core        import input_data, dropout, fully_connected\n",
    "from   tflearn.layers.conv        import conv_2d, max_pool_2d\n",
    "from   tflearn.layers.estimator   import regression\n",
    "from   tflearn.data_preprocessing import ImagePreprocessing\n",
    "from   tflearn.data_augmentation  import ImageAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_paths(foldNames):\n",
    "  \n",
    "    paths = dict.fromkeys(foldNames)\n",
    "\n",
    "    for idx,g in enumerate(foldNames):\n",
    "        fileNames = [f for f in listdir(join(trainPath,g)) if isfile(join(trainPath,g, f))]\n",
    "        for i,f in enumerate(fileNames):\n",
    "            fileNames[i] = join(trainPath,g,f)     \n",
    "        paths[g] = fileNames\n",
    "        \n",
    "    return paths\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = io.imread(src)\n",
    "    im = resize(im, (ROWS, COLS))\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.7 ms, sys: 49.3 ms, total: 90.9 ms\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ROWS           = 2 #60   90 720\n",
    "COLS           = 80 #80    160 1280\n",
    "CHANNELS       = 3\n",
    "NUM_CATEGORIES = 8\n",
    "\n",
    "trainPath      = '../data/raw/train'\n",
    "testPath       = '../data/raw/test_stg1'\n",
    "submitPath     = '../data/raw'\n",
    "fish_classes   = [f for f in listdir(trainPath) if isdir(join(trainPath, f))]\n",
    "groupData      = pd.DataFrame ({'group': fish_classes})\n",
    "fish_paths     = get_paths(fish_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build x and y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALB' 'ALB' 'ALB' ..., 'YFT' 'YFT' 'YFT']\n",
      "CPU times: user 7.24 ms, sys: 759 Âµs, total: 8 ms\n",
      "Wall time: 7.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for idx,fish in enumerate(fish_classes):\n",
    "    groupData.ix[idx,'num files'] = int(len(fish_paths[fish]))\n",
    "    \n",
    "files = []\n",
    "Y_cat = []\n",
    "\n",
    "for fish in fish_classes:\n",
    "    fish_files = fish_paths[fish]\n",
    "    files.extend(fish_files)\n",
    "    \n",
    "    y_fish = np.tile(fish, len(fish_files))\n",
    "    Y_cat.extend(y_fish)\n",
    "  \n",
    "Y_cat = np.array(Y_cat) \n",
    "print(Y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 3777\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, f in enumerate(files): \n",
    "    im = read_image(f)\n",
    "    X_all[i] = im\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view resampled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = X_all[0]\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(im, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data\n",
    "* One hot encoding labels\n",
    "* Split data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding Labels\n",
    "#    Transform the categorical array Y_all into matrix of the same height, \n",
    "#    but with a boolean column for each category.\n",
    "Y_all = LabelEncoder().fit_transform(Y_cat)\n",
    "Y_all = tflearn.data_utils.to_categorical(Y_all, NUM_CATEGORIES)\n",
    "\n",
    "# test_size: between 0 and 1. proportion of the dataset to include in the test split\n",
    "# random_state: Pseudo-random number generator state used for random sampling. How to shoose this?\n",
    "# stratify: this is ensuring that the split datasets are balanced, i.e. contains the same \n",
    "# percentage of classes\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_all, Y_all, \n",
    "                                                    test_size=0.2, random_state=23, \n",
    "                                                    stratify=Y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# read in test photo set\n",
    "test_files = [im for im in os.listdir(testPath)]\n",
    "test       = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "for i, im in enumerate(test_files): \n",
    "    test[i] = read_image(join(testPath,im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dnn_test1():\n",
    "    #needed to run this tensorflow operation in order to build the network and subsequently \n",
    "    #create the model, multiple times. Rebuilding without resetting the tf.Graph object produces\n",
    "    #errors. Could also get around this issue by restarting kernel, but that's annoying.\n",
    "    with tf.Graph().as_default():\n",
    "    \n",
    "    \n",
    "#         # Real-time data preprocessing\n",
    "#         img_prep = ImagePreprocessing()\n",
    "#         img_prep.add_featurewise_zero_center()\n",
    "        \n",
    "        \n",
    "#         # Convolutional network building\n",
    "#         network = input_data(shape=[None, ROWS, COLS, CHANNELS], \n",
    "#                             data_preprocessing=img_prep)\n",
    "\n",
    "        # input layer\n",
    "        network = input_data(shape=[None, ROWS, COLS, CHANNELS]\n",
    "                            )\n",
    "        \n",
    "        # hidden layers\n",
    "        network = conv_2d(network, 32, 3, activation='relu', regularizer='L2')\n",
    "        network = max_pool_2d(network, 2)\n",
    "        network = conv_2d(network, 64, 3, activation='relu', regularizer='L2')\n",
    "        network = conv_2d(network, 64, 3, activation='relu', regularizer='L2')\n",
    "        network = max_pool_2d(network, 2)\n",
    "        network = fully_connected(network, 512, activation='relu', regularizer='L2')\n",
    "        network = dropout(network, 0.5)\n",
    "        \n",
    "        \n",
    "        # output layer\n",
    "        network = fully_connected(network, NUM_CATEGORIES, activation='softmax', regularizer='L2')\n",
    "        network = regression(network, \n",
    "                             loss='categorical_crossentropy',\n",
    "                             learning_rate=0.01)\n",
    "        return tflearn.DNN(network, \n",
    "                           tensorboard_verbose=0)\n",
    "\n",
    "# Define model\n",
    "model = dnn_test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Start training (apply gradient descent algorithm). Will want to specify multiple epochs \n",
    "# typically unless just testing\n",
    "\n",
    "\n",
    "# Train using classifier\n",
    "model.fit(X_train, Y_train, \n",
    "          n_epoch        = 50, \n",
    "          shuffle        = True, \n",
    "          validation_set = (X_valid, Y_valid),\n",
    "          show_metric    = True, \n",
    "          batch_size     = 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict & save to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#model predict\n",
    "test_preds1 = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "submission = pd.DataFrame(test_preds1, columns=fish_classes)\n",
    "submission.insert(0, 'image', test_files)\n",
    "submission.to_csv(join(submitPath,'jfa-2.0-submission.csv'), \n",
    "                 index=False) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_prediction(jImage):\n",
    "    im = read_image(join(testPath, submission.image[jImage]))\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(im, cmap='gray', interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    foo = submission.iloc[jImage,1:]\n",
    "    print(foo.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_samples = 20\n",
    "for i in range(num_samples):\n",
    "    sample_prediction(np.random.randint(low=0, high=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def show_images(images,titles=None):\n",
    "#     \"\"\"Display a list of images\"\"\"\n",
    "#     n_ims = len(images)\n",
    "#     if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "#     fig = plt.figure()\n",
    "#     n = 1\n",
    "#     for image,title in zip(images,titles):\n",
    "#         a = fig.add_subplot(1,n_ims,n) # Make subplot\n",
    "#         if image.ndim == 2: # Is image grayscale?\n",
    "#             plt.gray() # Only place in this blog you can't replace 'gray' with 'grey'\n",
    "#         plt.imshow(image)\n",
    "#         a.set_title(title)\n",
    "#         print(submission.iloc[jImage,:])\n",
    "\n",
    "#         n += 1\n",
    "#     fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
